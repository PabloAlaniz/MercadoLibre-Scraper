# Roadmap â€” MercadoLibre Scraper

> Ãšltima actualizaciÃ³n: 2026-02-19

## âœ… Implementado

### Core
- **Clean Architecture** â€” Dominio, aplicaciÃ³n, infraestructura y presentaciÃ³n desacoplados
- **Multi-paÃ­s** â€” 18 paÃ­ses de LATAM soportados (AR, MX, BR, CL, CO, etc.)
- **Interfaz dual** â€” Dashboard web (Dash) + CLI

### Scrapers
- **MercadoLibreScraper** â€” Productos generales con paginaciÃ³n
- **CarScraper** â€” Especializado para autos (km, aÃ±o, motor)
- **PropertyScraper** â€” Especializado para inmuebles (mÂ², ambientes)

### Dominio
- **Entidades** â€” `ProductListing`, `ProductDetail`, `CarProductDetail`, `PropertyProductDetail`
- **Value Objects** â€” `Money`, `Kilometers`, `SquareMeters` con parsing y conversiÃ³n
- **Ports** â€” Interfaces para scrapers, exportadores, notificadores, exchange rates

### Infraestructura
- **CsvExporter** â€” ExportaciÃ³n a CSV con separador configurable
- **DolarApiExchangeRate** â€” ConversiÃ³n USD â†” ARS via DolarAPI
- **SocketIOProgressNotifier** â€” Notificaciones en tiempo real al dashboard
- **NullProgressNotifier** â€” Para CLI y tests

### PresentaciÃ³n
- **Dashboard Dash** â€” UI interactiva con grÃ¡ficos y tablas
- **Selector de paÃ­s** â€” Dropdown con 18 paÃ­ses
- **Progreso en tiempo real** â€” Via Flask-SocketIO

### Quality
- **127 tests unitarios** â€” Cobertura de domain, application, infrastructure, presentation
- **23 tests de integraciÃ³n** â€” Requests reales a MercadoLibre
- **CI/CD** â€” GitHub Actions ejecuta tests en cada push/PR

## ğŸš§ En progreso

*(nada actualmente)*

## ğŸ“‹ Backlog

### Corto plazo (v1.x)
- [ ] **Input pÃ¡ginas** â€” Permitir al usuario elegir cantidad de pÃ¡ginas a scrapear
- [ ] **GrÃ¡fico distribuciÃ³n de precios** â€” Histograma de precios en el dashboard
- [ ] **Export Excel** â€” ExportaciÃ³n a .xlsx ademÃ¡s de CSV

### Mediano plazo (v2.x)
- [ ] **Docker support** â€” Dockerfile + docker-compose para deploy fÃ¡cil
- [ ] **API REST** â€” Endpoints para scraping on-demand (FastAPI)
- [ ] **Scheduled scraping** â€” Cron jobs para monitoreo periÃ³dico
- [ ] **Base de datos** â€” PostgreSQL o SQLite para persistir resultados

### Arquitectura (ya preparado)
- [ ] **Nuevo retailer** â€” Agregar scrapers para Amazon, eBay, etc. (Container ya soporta multi-retailer)

## ğŸ’¡ Ideas

- **Rate limiting inteligente** â€” Backoff automÃ¡tico cuando se detecta throttling
- **Proxy/Tor support** â€” RotaciÃ³n de IPs para scraping masivo
- **HistorizaciÃ³n de precios** â€” Tracking de precio en el tiempo (requiere DB)
- **Alertas de precio** â€” Notificar cuando un producto baja de cierto umbral
- **Comparador** â€” Comparar precios del mismo producto entre paÃ­ses
- **Export BigQuery** â€” IntegraciÃ³n directa para anÃ¡lisis de datos
- **Playwright mode** â€” Scraping de pÃ¡ginas con JS rendering (ya existe `playwright_client.py`)

---
*Generado por BrÃºjula ğŸ§­*
